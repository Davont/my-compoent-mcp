Anthropic 又发布了一篇神级指南。

这次的主题是：如何构建更高效的 AI 智能体 (AI Agent)，让它们能更聪明地使用工具，并且极大地节省 Token 。

如果你是 AI 开发者，这篇文章绝对不容错过！

它主要解决了 AI 智能体在调用工具时遇到的三大难题：Token 成本、延迟 (latency) 和工具组合的效率。

怎么做到的？简单来说，它把“代码执行”和“模型编写的代码” (MCP, Model-Written Code) 结合了起来。它不再让 AI 智能体直接去“调用工具”，而是把这些工具“伪装”成代码 API，让 AI 智能体像程序员一样通过写代码来使用它们。

以下是这篇指南的核心干货：

1. Token 效率的“黑洞”：想象一下，如果 AI 智能体一上来就把所有可能用到的工具定义全塞进大脑（上下文窗口 (context window)），并且在执行任务时，每一步的中间结果都塞回去。这样会导致 Token 开销大到爆炸，一个复杂的多工具任务跑下来，有时会超过 15 万个 Token。

2. “代码即 API” 策略：新方法是，不直接调用工具，而是把这些“模型编写的代码” (MCP) 工具包打包成代码 API（比如 TypeScript 模块）。AI 智能体可以像程序员一样“导入” (import) 并通过编程来调用它们。效果立竿见影：一个 15 万 Token 的任务，瞬间被压缩到了 2000 个 Token，节省了 98.7%！

3. 工具的“渐进式发现”：不再一股脑加载所有工具。AI 智能体学会了“按需取用”，通过搜索文件系统或调用 search_tools（搜索工具）函数，只在需要时才加载当前任务相关的工具定义。这完美解决了“上下文臃肿” (context rot) 和 Token 过载的问题。

4. “数据本地处理”：在把结果喂给大语言模型 (LLM) 之前，先在代码执行环境里把数据处理好（比如筛选、转换、汇总）。举个例子：AI 智能体不需要查看 1 万行的表格，代码环境会先帮它筛选出那 5 行最重要的，再交给它。

5. 更优的控制流 (Control Flow)：与其让 AI 智能体一步步地“指挥”工具（比如“做完A，再做B”），不如直接用代码原生的循环 (loops)、条件判断 (conditionals) 和错误处理来管理流程。这样做，既减少了延迟，也省了 Token。

6. 隐私保护：敏感数据可以在整个工作流中传递，而完全不进入大模型的“视野”（上下文）。只有那些被明确指定“返回”或“记录”的值才会被模型看到，还可以选择自动对个人身份信息 (PII) 进行脱敏。

7. 状态持久化 (State Persistence)：AI 智能体可以把中间结果存成文件，“断点续传”。这样一来，它们就能处理那些需要跑很久的“大任务”，并且能跟踪进度。

8. 可复用的“技能包”：AI 智能体可以把写好的有效代码保存成“可复用函数”（并配上 SKILL .MD 文档），久而久之，它就能积累出一个强大的高级“技能库”。

这种方法虽然更复杂，也还不完美，但它绝对能全面提升你构建的 AI 智能体的效率和准确性。